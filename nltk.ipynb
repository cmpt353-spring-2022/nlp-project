{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8753e620",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26ce5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529f87e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c7b1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename, clickbait):\n",
    "    df = pd.read_csv(filename)\n",
    "    df.drop_duplicates(subset='url', inplace=True)\n",
    "    df['title'] = df['title'].str.strip()\n",
    "    df['title'] = df['title'].str.split('https://url4ever.com').str[0].str.strip()\n",
    "    df['title'] = df['title'].str.split('- reuters').str[0].str.strip()\n",
    "    \n",
    "    autonp_prefixes = ['[economy] -', '[arts] -', '[op-ed] -', '[national] -', '[world] -', '[politics] -', '[local] -', '[video] -', '[sports] -', '[business] -', '[entertainment] -', '[tech] -', '[science] -', '[health] -']\n",
    "    df['title'] = df['title'].apply(lambda x: presplit(x, autonp_prefixes))\n",
    "    autonp_postfixes = ['| pbs', '| cnn', '| sydney morning herald', '| chicago tribune', '| chicago sun-times', 'la times', 'iol', '| al jazeera', '| washington post', '| toronto star', '| telegraph', '| bbc', '| south china morning post', '| npr', '| guardian', '| the japan times', '| abc', '| fox', '| al arabiya', '| nbc', '| irish times', '| manila bulletin', '| nz herald', '| times of india', '| sana', '| usatoday', '| nypost']\n",
    "    df['title'] = df['title'].apply(lambda x: postsplit(x, autonp_postfixes))\n",
    "    \n",
    "    ap_prefixes = ['(ap:)', 'ap report:', 'ap investigation:', 'ap poll:', 'ap analysis:', 'ap sources:', 'ap source:', 'ap fact check:', '[ap news]', 'ap photos:', 'ap news:', 'ap:', 'ap interview:', 'the ap interview:']\n",
    "    df['title'] = df['title'].apply(lambda x: presplit(x, ap_prefixes))\n",
    "    ap_postfixes = ['- associated press', '| ap news', '| february 24, 2021', '[ap]', '(ap)']\n",
    "    df['title'] = df['title'].apply(lambda x: postsplit(x, ap_postfixes))\n",
    "    \n",
    "    other_prefixes = ['news brief:', 'bbc:', 'watch:', 'reuters:', 'watch live:', 'breaking:', 'the latest:']\n",
    "    df['title'] = df['title'].apply(lambda x: presplit(x, other_prefixes))\n",
    "    other_postfixes = []\n",
    "    df['title'] = df['title'].apply(lambda x: postsplit(x, other_postfixes))\n",
    "    \n",
    "    banned = ['ap poll', 'reuters', 'pbs', 'npr', 'apnews', 'associated press', 'savedyouaclick']\n",
    "    for term in banned:\n",
    "        df = df[df['title'].str.contains(term, regex=False) == False]\n",
    "    \n",
    "    df.drop_duplicates(subset='title', inplace=True)\n",
    "    df = df[['created_utc', 'title', 'score']]\n",
    "    df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "    df['clickbait'] = clickbait\n",
    "    \n",
    "    return df\n",
    "\n",
    "def presplit(title, prefixes):\n",
    "    for pre in prefixes:\n",
    "        if title.startswith(pre):\n",
    "            return title.split(pre)[1].strip()\n",
    "    \n",
    "    return title\n",
    "    \n",
    "def postsplit(title, postfixes):\n",
    "    for post in postfixes:\n",
    "        if title.endswith(post):\n",
    "            return title.split(post)[0].strip()\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b815b83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load clickbait sources\n",
    "clickbait = load_csv('clickbait.csv.gz', 1)\n",
    "clickbait = clickbait[clickbait['title'].str.contains('|', regex=False)]\n",
    "clickbait['title'] = clickbait['title'].str.split('|').str[0].str.strip()\n",
    "clickbait.drop_duplicates(subset='title', inplace=True)\n",
    "clickbait = clickbait[clickbait['title'].notna()]\n",
    "clickbait = clickbait[clickbait['score'] > 5]\n",
    "#display(clickbait)\n",
    "\n",
    "# load non-clickbait sources\n",
    "apnews = load_csv('apnews.csv.gz', 0)\n",
    "npr = load_csv('npr.csv.gz', 0)\n",
    "pbs = load_csv('pbs.csv.gz', 0)\n",
    "reuters = load_csv('reuters.csv.gz', 0)\n",
    "news = pd.concat([apnews, reuters, npr, pbs], ignore_index=True)\n",
    "#display(news)\n",
    "\n",
    "# ensure balance between clickbait and non-clickbait entries\n",
    "clickbait = clickbait.sample(min(clickbait.shape[0], news.shape[0]), ignore_index=True)\n",
    "news = news.sample(min(clickbait.shape[0], news.shape[0]), ignore_index=True)\n",
    "#display(clickbait)\n",
    "#display(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62afe677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why Song of the South is the Movie Disney Does...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There's one good reason to update to macOS Hig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He's Been Secretly Taking Pictures Of His Best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ukrainian sailors tried to block a Russian oli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Death toll rises after Ida’s remnants hit Nort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21713</th>\n",
       "      <td>EXCLUSIVE U.S. asks Japan, China, others to co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21714</th>\n",
       "      <td>SK Innovation to invest $4.3 bln in U.S. batte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21715</th>\n",
       "      <td>[National] - In ‘Scranton Lace,’ nostalgia for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21716</th>\n",
       "      <td>Word Leaks Out About Hillary's Post-Election C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21717</th>\n",
       "      <td>Babies are born 18 hours apart, then photograp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21718 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  clickbait\n",
       "0      Why Song of the South is the Movie Disney Does...          1\n",
       "1      There's one good reason to update to macOS Hig...          1\n",
       "2      He's Been Secretly Taking Pictures Of His Best...          1\n",
       "3      Ukrainian sailors tried to block a Russian oli...          0\n",
       "4      Death toll rises after Ida’s remnants hit Nort...          0\n",
       "...                                                  ...        ...\n",
       "21713  EXCLUSIVE U.S. asks Japan, China, others to co...          0\n",
       "21714  SK Innovation to invest $4.3 bln in U.S. batte...          0\n",
       "21715  [National] - In ‘Scranton Lace,’ nostalgia for...          0\n",
       "21716  Word Leaks Out About Hillary's Post-Election C...          1\n",
       "21717  Babies are born 18 hours apart, then photograp...          1\n",
       "\n",
       "[21718 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.concat([clickbait, news], ignore_index=True)\n",
    "data = data[['title', 'clickbait']]\n",
    "data = data.sample(frac=1, ignore_index=True)\n",
    "\n",
    "data.to_csv(\"filtered.csv.gz\", compression='gzip', index=False)\n",
    "\n",
    "display(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
